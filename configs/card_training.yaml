data:
  train:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.altheia_dataset
        class: AltheiaDataset
        AltheiaDataset:
          compound_coef: 0
          dirname: '''dataset/EKYCs/train'''
          image_patterns: ['''*.jpg''', '''*.png''', '''*.jpeg''', '''*.JPG''', '''*.PNG''', '''*.JPEG''']
          label_patterns: ['''*.xml''']
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          classes:
            BLX: 0
            BLX_BACK: 1
            BLX_OLD: 2
            BLX_BACK_OLD: 3
            CMND: 4
            CMND_BACK: 5
            CCCD: 6
            CCCD_BACK: 7
            CMCC: 8
            CCCD_front_chip: 9
            CCCD_back_chip: 10
            CMQD_A: 11
            CMQD_A_BACK: 12
            CMQD_B: 13
            CMQD_B_BACK: 14
            CMQD_C: 15
            CMQD_C_BACK: 16
            CMQD_D: 17
            CMQD_D_BACK: 18
            CMQD_B_VT: 19
            CMQD_B_VT_BACK: 20
            PASSPORT: 21
            PASSPORT_OTHER: 22
          transforms:
            - iaa.MotionBlur()
            - iaa.ChangeColorTemperature()
            - iaa.GaussianBlur(sigma=(0, 1))
            - iaa.Grayscale(alpha=(0.0, 1.0))
            - iaa.Add(value=(-50, 50), per_channel=True)
            - iaa.Fliplr(p=0.5)
            - iaa.Flipud(p=0.5)
            - iaa.Crop(percent=(0, 0.1))
            - iaa.Pad(percent=(0, 0.1), keep_size=False)
            - iaa.Rot90(k=[0, 1, 2, 3], keep_size=False)
            - iaa.Affine(rotate=(0, 360), shear=(-2, 2), fit_output=True)
      batch_size: 32
      shuffle: True
      num_workers: 12
      pin_memory: True
      drop_last: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'
  
  train_eval:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.altheia_dataset
        class: AltheiaDataset
        AltheiaDataset:
          compound_coef: 0
          dirname: '''dataset/EKYCs/train'''
          image_patterns: ['''*.jpg''', '''*.png''', '''*.jpeg''', '''*.JPG''', '''*.PNG''', '''*.JPEG''']
          label_patterns: ['''*.xml''']
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          classes:
            BLX: 0
            BLX_BACK: 1
            BLX_OLD: 2
            BLX_BACK_OLD: 3
            CMND: 4
            CMND_BACK: 5
            CCCD: 6
            CCCD_BACK: 7
            CMCC: 8
            CCCD_front_chip: 9
            CCCD_back_chip: 10
            CMQD_A: 11
            CMQD_A_BACK: 12
            CMQD_B: 13
            CMQD_B_BACK: 14
            CMQD_C: 15
            CMQD_C_BACK: 16
            CMQD_D: 17
            CMQD_D_BACK: 18
            CMQD_B_VT: 19
            CMQD_B_VT_BACK: 20
            PASSPORT: 21
            PASSPORT_OTHER: 22
      batch_size: 32
      shuffle: False
      num_workers: 12
      pin_memory: True
      drop_last: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'
  
  valid:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.altheia_dataset
        class: AltheiaDataset
        AltheiaDataset:
          compound_coef: 0
          dirname: '''dataset/EKYCs/valid'''
          image_patterns: ['''*.jpg''', '''*.png''', '''*.jpeg''', '''*.JPG''', '''*.PNG''', '''*.JPEG''']
          label_patterns: ['''*.xml''']
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          classes:
            BLX: 0
            BLX_BACK: 1
            BLX_OLD: 2
            BLX_BACK_OLD: 3
            CMND: 4
            CMND_BACK: 5
            CCCD: 6
            CCCD_BACK: 7
            CMCC: 8
            CCCD_front_chip: 9
            CCCD_back_chip: 10
            CMQD_A: 11
            CMQD_A_BACK: 12
            CMQD_B: 13
            CMQD_B_BACK: 14
            CMQD_C: 15
            CMQD_C_BACK: 16
            CMQD_D: 17
            CMQD_D_BACK: 18
            CMQD_B_VT: 19
            CMQD_B_VT_BACK: 20
            PASSPORT: 21
            PASSPORT_OTHER: 22
      batch_size: 32
      shuffle: False
      num_workers: 12
      pin_memory: True
      drop_last: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'

loss:
  module: flame.core.loss.focal_loss
  class: FocalLoss
  FocalLoss:
    alpha: 0.25
    gamma: 2.0
    lamda: 50.0
    device: '''cuda'''

model:
  module: flame.core.model.EfficientDet.efficientdet
  class: EfficientDet
  EfficientDet:
    pretrained_weight: '''checkpoint/efficientdet_pretrained_weight/efficientdet-d0.pth'''
    head_only: False
    num_classes: 23
    compound_coef: 0
    backbone_pretrained: False
    scales: ['2 ** 0', '2 ** (1.0 / 3.0)', '2 ** (2.0 / 3.0)']
    aspect_ratios: ['(1.0, 1.0)', '(1.4, 0.7)', '(0.7, 1.4)']

optim:
  module: torch.optim
  class: SGD
  SGD:
    params: config['model'].parameters()
    lr: 0.08
    momentum: 0.9
    nesterov: True

train_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['train_eval']
    device: '''cuda'''

valid_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['valid']
    device: '''cuda'''

metrics:
  module: flame.handlers.metrics.metrics
  class: Metrics
  Metrics:
    metrics:
      focal_loss:
        module: flame.handlers.metrics.focal_loss.loss
        class: Loss
        Loss:
          loss_fn:
            module: flame.handlers.metrics.focal_loss.focal_loss
            class: FocalLoss
            FocalLoss:
              alpha: 0.25
              gamma: 2.0
              lamda: 50.0
              device: '''cuda'''
          output_transform: 'lambda x: (x[0], x[1], x[2], x[3])'
    attach_to:
      train_evaluator: '''train'''
      valid_evaluator: '''valid'''

screenlogger:
  module: flame.handlers.screenlogger
  class: ScreenLogger
  ScreenLogger:
    eval_names:
      - '''train''' 
      - '''valid'''

history:
  module: flame.handlers.checkpoint
  class: History

checkpoint_loader:
  module: flame.handlers.checkpoint
  class: CheckpointLoader
  CheckpointLoader:
    checkpoint_path: ''''''
    mode: '''train'''

terminate_on_nan:
  module: flame.handlers.terminate_on_nan
  class: TerminateOnNan

lr_scheduler:
  module: flame.handlers.lr_scheduler
  class: ReduceLROnPlateau
  ReduceLROnPlateau:
    score_name: '''focal_loss'''
    evaluator_name: '''valid_evaluator'''
    mode: '''min'''
    patience: 3
    verbose: True

early_stopping:
  module: flame.handlers.early_stopping
  class: EarlyStopping
  EarlyStopping:
    score_name: '''focal_loss'''
    evaluator_name: '''valid_evaluator'''
    mode: '''min'''
    patience: 30

best_saver:
  module: flame.handlers.checkpoint
  class: BestSaver
  BestSaver:
    dirname: '''checkpoint/EKYCS/efficientdet-d0'''
    score_name: '''focal_loss'''
    mode: '''min'''
    evaluator_name: '''valid_evaluator'''
    n_saved: 1

backup_saver:
  module: flame.handlers.checkpoint
  class: BackupSaver
  BackupSaver:
    modules:
      - '''model'''
      - '''optim'''
      - '''backup_saver'''
      - '''best_saver'''
      - '''history'''
      - '''lr_scheduler'''
      - '''early_stopping'''
    dirname: '''checkpoint/EKYCS/efficientdet-d0'''
    save_interval: 1
    n_saved: 1

engine:
  module: flame.core.engine.trainer
  class: Trainer
  Trainer:
    dataset: config['data']['train']
    device: '''cuda'''
    max_epochs: 10000
    max_norm: 0.1
    norm_type: 2

extralibs:
  torch: torch
  iaa: imgaug.augmenters
